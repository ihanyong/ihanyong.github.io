For streaming applications with small state, these snapshots are very light-weight and can be drawn frequently without much impact on performance. The state of the streaing applications is stored at a configurable place.

In case of a program failure(due to machine-, network-, or software failure), Flink stops the distributed streaming dataflow. The system then restarts the operators and resets them to the latest successful checkpoint. The input streams are reset to the point of the state snapshot. Any records that are processed as part of the restarted parallel dataflow are guaranteed to not have been part of the previously checkpointed state.

### Checkpointing

The central part of Flink's fault tolerance mechanism is drawing consistent snapshots of the distributed data stream and operator state. These snapshots act as consistent checkpoints to which the system can fall back in case of a failure. Flink's mechanism for drawing these snapshots is described in "Lightweight Asynchronous Snapshots for Distributed Dataflows", It is inspired by the standard Chandy-lamport algorithm for distributed snapshots and is specifically tailored to Flink's exection model.

#### Barriers
A core element in Flink's distributed snapshots are the stream barriers. These barriers are injected into the data stream and flow with the records as part of the data stream. Barriers never overtake records, the flow strictly in line. A barrier separates the records in the data stream into the set of records that goes into the current snapshot, and the records that go into the next snapshot. Each barrier carries the ID of the snapshot whose records it pushed in front of it. Barriers do not interrupt the flow of the stream and are hence very lightweight. Multiple barriers from different snapshots can be in the stream at the same time, which means that various snapshot may happen concurrently. 

Stream barriers are inject into the parallel data flow at the stream sources. The point where the barriers for snapshot n are injected (let's call it s-n) is the position in the source stream up to which the snapshot covers the data. For example, in Apache Kafka, this position would be the last record's offset in the partition. This position S-n is reported to the checkpoint corrdinator(Flink's JobManage).




把计算sink到mysql里，且实现TwoPhaseCommit， 会不会就不是个好的想法呢？ 
1.  如果是大数据量的场景存到mysql是否合适？ 
2.  量相对不大的聚合数据sink到 mysql 是不是应该在业务代码上使用保证幂等性的更新方式， 而不是依赖 flink 做 exactly once 的保证

