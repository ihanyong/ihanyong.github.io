2018-09-28-Java并发编程

# 第2章 线程安全性
如果当多个线程访问同一个可变的状态变量时没有使用合适的同步，那么程序应付出现错误。有有一种方式可以修复这个问题：
- 不在线程之间共享该状态变量。
- 将状态变量修改为不可变的变量。
- 在肩部状态变量时使用同步。

## 2.1 什么是线程安全性
线程安全性的定义中，最核心的概念就是正确性。
正确性的含义是，某个类的行为与其规范完全一致。
不变性条件来约束对象的状态， 各种后验条件来描述对象操作的结果。

在线程安全类中封装了必要的同步机制，因此客户端无需进一步采取同步措施。

无状态对象一定是线程安全的。


## 2.2 原子性
### 2.2.1 竞态条件  race condition
正确的结果取决于运气
Check-Then-Act, 通过一个可能失效的观测结果来决定下一步的动作。

### 2.2.2 示例延迟初始化的竞态条件
竞态条件并不问题会产生错误，还需要某种不恰当的执行时序。

### 2.2.3 复合操作
lazyInitRace 和 UnsafeContionFactorizer 都包含一组需要以原子方式执行的操作。要避免竞态条件问题，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或者之后读取和修改状态，而不是在修改状态的过程中。

## 2.3 加锁机制
在线程安全性的定义中要求，多个线程之间的操作无论采用何种执行时序或交替方式，都要保证不变性条件不被破坏。

要保持状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。

###  2.3.1 内置锁
Java提供了一种内置的锁机制来支持原子性：同步代码块（Synchroized Block）。
内置锁相当于一种互斥体（互斥锁）

###  2.3.2 重入
内置锁是可重入的。
重入意味着获取锁的操作的粒度是“线程”，而不是“调用”。

## 2.4 用锁保护状态
对于每个包含多个变量的不变性条件，其中涉及的所有变量都需要由同一个锁来保护。

## 2.5 活跃性与性能
通常，在简单性与性能之间存在着相互制约因素。当实现 某个同步策略时，一定不要盲目地为了性能而牺牲简单性（这可能会破坏安全性）

当执行时间较长的计算或者可能 无法快速 完成的操作时（如I/O），一定不要持有锁。



# 第3章 对象的共享
编写正确的并发程序，关键问题在于：在访问共享的可变 状态时需要进行正确的管理。
同步还有另外一个重要的方面： 内存可见性（momory visibility)

## 3.1 可见性
在单线程环境中，如果向某个变量先写入值，然后在没有共创写入操作的情况下赢取这个变量，那么 总能得到相同的值。 当读与写操作在不同线程中执行时， 无法确保执行读操作的线程能适时地看到其他线程写入的值。

### 3.1.1 失效数据
读线程查看变量值时， 可能会得到一个已经失效的值。


### 3.1.2 非原子的64位操作
失效值至少是一个设置过的值， 不是随机值， 这种安全性保证被称为最低安全性(out-ofthin-airsafety)
最低安全性适用于绝大多数变量，有一个例外：非 volatile 类型的64位数值变量（double long）

### 3.1.3 加锁与可见性
加锁的含义不仅仅局限于互斥行为，还包括内存可见性。 为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者 写操作的线程都必须 在同一个锁上同步。

### 3.1.4 Volatile变量
读取 volatile 类型的变量时部会返回 最新写入的值。
典型用法： 状态标记检查

仅当volatile变量能简化代码的实现 以及对同步策略的验证时，才应该使用它们。

加锁机制即可心确保可见性又可以确保 原子性， 而volatile变量只能 确保 可见性。
当且仅当满足以下所有箱件时， 才应该使用volatile变量：
- 对变量的写入操作不依赖变量的当前值，或者能确保只有单个线程更新变量的值
- 该变量不会与其他状态变量一起纳入不变性条件
- 在访问变量时不需要加锁
- 

## 3.2 发布与逸出
## 3.3 线程封闭
### 3.3.1 Ad-hoc效果图看封闭
### 3.3.2 栈封闭
### 3.3.3 ThreadLocal类

## 3.4 不变性
#### 3.4.1 Final域
#### 3.4.2 示例：使用 Volatile 类型来发布不可变对象

## 3.5 安全发布
### 3.5.1 不正确的发布：正确的对象被破坏
### 3.5.2 不可变对象与初始化安全性
### 3.5.3 安全发布的常用模式
### 3.5.4 事实不可变对象
### 3.5.5 可变对象
### 3.5.6 安全地共享对象



#　第４章　对象的组合
## 4.1 设计线程安全的类
### 4.1.1 收集同步需求
### 4.1.2 依赖状态的操作
### 4.1.3 状态的所有权

## 4.2 实例封闭
### 4.2.1 Java监视器模式
### 4.2.2 示例：车辆追踪

## 4.3 线程安全性的委托
### 4.3.1 示例：基于委托的车辆追踪器
### 4.3.2 独立 的状态变量
### 4.3.3 当委托失效时
### 4.3.4 发布底层的状态变量
### 4.3.5 示例：发布状态的车辆追踪器

## 4.4 在现有的线程安全类中添加功能
### 4.4.1 客户端加锁机制
### 4.4.2 组合

## 4.5 将同步策略文档化


# 第5章
## 5.1 同步容器类
同步容器类包括 Vector 和 Hashtable, 二者是早期 JDK的 一部分， 此外还包括在JDK1.2 中添加的一些功能 相似的类， 这些同步 的封装器类是由 Collections.synchronizedXXX 等工厂方法创建的。 这些类实现 线程安全的方式 是： 将他们的状态封装起来， 并对第个仅有方法都进行同步， 使得每次只有一个线程访问容器的状态。


### 5.1.1 同步容器类的问题
需要额外的客户端加锁来保护复合操作。 常见的复合操作包括： 迭代、跳转以及箱件运算，如 “没有则添加”。 


### 5.1.2 迭代器与Concurrent-ModificationException
在设计同步容器类的迭代器时并没有考虑到并发修改的问题， 并且他们表现出的行为 是“及时失败”的， 即会抛出一个ConcurrentModificationException
不希望在迭代期间对容器加锁， 一种替代方法是“克隆” 容器， 并在副本上进行迭代。



### 5.1.3 隐藏迭代器
迭代器会隐藏起来， 隐匿调用。
状态与保护它的同步代码 之间相隔越远， 那么开发人员就越容易忘记在肩部状态 时使用正确的同步。


##  5.2 并发容器
ConcurrentHashMap -> HashMap
CopyOnWirteArrayList -> ArrayList
ConcurrentSkipListMap -> SortedMap
ConcurrentSkipListSet -> SortedSet

Queue、 BlockingQueue。

通过并发容器来代替同步容器，可以极大地提高伸缩性并降低风险。


### 5.2.1 ConcurrentHashMap
### 5.2.2 额外的原子Map操作
### 5.2.3 CopyOnWirteArrayList
## 5.3 阻塞队列和生产者-消费者模式
### 5.3.1 示例：桌面搜索
### 5.3.2 串行线程封闭
### 5.3.3 双端队列与工作密取

## 5.4 阻塞方法与中断方法

## 5.5 同步工具类
### 5.5.1 闭锁
### 5.5.1 FutureTask
### 5.5.1 信号量
### 5.5.1 栅栏

##  5.6 构建高效且可伸缩的结果缓存


# 第6章 任务执行
大多数并发应用程序都是围绕“任务执行”来构造 的： 任务通常是一些抽象的离散工作单元。
通过 把应用程序 的工作分解到多个任务中，可以简化程序的组织结构，提供一种自然 的事务边界来优化错误恢复过程，以及提供一种自然 的并行工作结构来提升并发性。

## 6.1 在线程中执行任务
第一步就是要找出清晰的任务边界。
理想情况下，各个任务之间是相互独立的： 任务并不依赖于其他任务的状态，结果或边界效应。
为了在高度与负载均衡过程中实现 更高 的灵活性，每项任务还应该表示应用程序 的一小部分处理能力。

在正常的负载下，服务器应用程序 应该購表现出良好的吞吐量和快速 的响应性。
提供商希望支持尽可能多的用户， 用户希望获得尽快的响应。
一种自然的任务边界：以独立 的客户请求为边界。 既可以实现任务的独立性，又可以实现合理的任务规模

### 6.1.1 串行地执行任务
可以通过多种上策略来高度任务。
最简单的策略就是在单个 线程中串行地执行各项任务。
-> 简单，理论上正确， 性能却很糟糕。

### 6.1.2 显式地为任务创建线程
通过 为每个请求创建一个新的线程来提供服务，从而实现更高的响应性，
- 任务处理过程从主线程中分离出来，使得主循环能更快重新等待下一个到来的连接， 提高响应性
- 任务可以并行处理，从而 能同时服务多个请求。 吞吐量得到提高。
- 任务处理代码 必须是线程安全的

### 6.1.3 无限抽创建线程的不足
- 线程生命周期的开销非常高。
- 资源消耗。
- 稳定性。

在一定的范围内， 增加线程可以提高 系统的吞吐率，但如果 超出了这个范围，再创建更多的线程只会降低程序的执行速度 ，甚至程序将崩溃。
应该限制可创建的线程数，确保不会耗尽资源。

## 6.2 Executor 框架
任务是一组逻辑工作单元 ， 而线程则是使任务异步执行的机制。
线程池简化 了线程的管理工作， 并且 java.util.concurrent提供了一种灵活的线程池实现作为Executor框架的一部分。
在java类库中，任务执行的主要抽象不是thread, 而是Executor。
Executor是个简单的接口，提供 了标准的方法将任务的提交过程与执行过程解耦， 用Runnable来表示任务。
Executor的实现 还提供了对生命周期的支持，以及统计 信息收集、应用程序管理机制和性能监视等机制。

Executor基于生产者-消费者模式， 提交任务的操作相当于生产者， 执行任务的线程则相当于消费者。
如果要在程序中实现一个生产者-消费者的设计， 最简单的方式 通常就是使用Executor.


### 6.2.1 示例：基于Executor的Web服务器
### 6.2.2 执行策略
通过将任务的提交与执行解耦，从而 无须太大的困难就可以为草种类型的任务指定和悠执行策略。
在执行策略中定义了任务执行的“ What、Where、When、How” 等方面， 包括：
- 在什么线程中执行任务
- 任务按照什么顺序执行
- 有多个个任务能并发执行
- 在队列中有多少个任务在等待执行
- 如果系统由于过载而拒绝一个任务，那么应该选择哪一个？如何通知应用程序有任务被拒绝？
- 在执行一个任务之前 或之后 ，应该进行哪些动作？

每当看到下面这种形式的代码时， 并且希望获得一生中更灵活 的执行策略时， 请考虑使用Executor来代替Thread。
new Thread(runnable).start();

### 6.2.3 线程池
字面含义，是指管理一组同构工作线程的资源池。 线程池是与工作队列密切相关的，在工作队列中保存了所有等待执行的任务。
工作都线程的任务很简单：从工作队列中获取一个任务，执行任务，然后返回线程池并等待下一个任务。

服务器不会创建数千个线程来争夺有限的CPU和内存资源，因此服务器的性能 将平缓地降低。
通过使用Executor， 可以实现 各种高估、管理 监视、记录日志、错误报告和其他 功能。

### 6.2.4 Executor的生命周期
JVM只有在所有 的（非守护）线程全部终止后才会退出，因此，如果无法正确地关闭Executor，JVM将无法结束。
为了解决执行服务 的生命周期问题， Executor扩展了ExecutorService接口， 添加一一些用于生命周期管理的方法（还有一些用于任务提交 的便利方法）。

ExecutorService的生命周期有3种状态： 运行、关闭和已终止



### 6.2.5 延迟任务的周期任务

## 6.3 找出可利用的并行性
### 6.3.1 示例：串行的页面渲染器
### 6.3.2 携带结果的任务 Callable 与Future
### 6.3.3 示例：使用Future实现页面渲染器
### 6.3.4 在异构任务并行化中存在的局限
### 6.3.5 CompletionService: Executor 与 BlockingQueue
### 6.3.6 示例：使用CompletionService实现 页面渲染器
### 6.3.7 为任务设置时限
### 6.3.8 示例：旅行预定门户网站






第7章 取消与关闭
Java没有提供任何机制来安全的终止线程。 但提供了中断 Interruption， 一种协作机制，能够使一个线程终止 另一个线程的当前工作。 
任务本身的代码 比发出 取消请求的代码更清楚 如何执行清除工作。

行为良好的软件 Vs. 勉强运行的软件： 行为良好的软件能很完善地处理失败，关闭和取消等过程。


7.1 任务取消
如果外部代码 能在 某个 操作正常完成 之前 将其置入 “完成 ” 状态 ， 那么这个操作就可以称为可取消的。 取消的原因很多：
- 用户请求取消
- 有时间限制 的操作
- 应用程序 事件
- 错误
- 关闭

Java中没有安全的抢占式方法来停止线程和任务。 只有一些协作式的机制：
- 设置某个“已请求取消”标志，任务将定期地查看该标志。
一个可取消的任务必须拥有取消策略， 在这个策略中将详细 地定义取消操作的“how， when， what” 即其他代码 请求取消任务， 任务在何时 检查是否已经 请求了取消， 以及在响应取消请求时应该执行哪些操作。

7.1.1 中断
对中断操作的正确理解是：它并不会真正地中断一个正在运行的线程， 而只是发出中断请求， 然后由线程在下一个全程的时刻中断自己。
通常，中断是实现 取消的最合理方式。

7.1.1 中断策略
线程同样应该包含中断策略：规定线程如何解释 某个 中断请求，当发现中断请求时，应该做哪些工作，哪些工作单元 对于 中断 来说是原子 操作，以及多快的速度 来响应中断。


最合理的中断 策略是某种形式的线程级取消操作或服务 级取消操作： 尽快退出 ， 在必要时进行清理 ， 能生在某个所有者该线程已经 退出。 

还可以建立其他的中断策略，例如暂停服务或重新开始服务。但对于那些包含非标准中断策略的线程或线程池，只能用于知道这些策略的任务中。

由于 每个线程拥有各自的中断策略，因此除非你知道中断对该线程的含义，否则就不应该中断这个线程。



7.1.1 响应中断
7.1.1 示例：计时运行
7.1.1 通过 Future 来实现取消
7.1.1 处理不可中断的阻塞
7.1.1 采用newTaskFor 来封装非标准的取消

7.2 停止基于线程的服务
7.2.1 示例：日志服务
7.2.1 关闭ExecutorService
7.2.1 “毒丸”对象
7.2.1 示例：只执行一次的服务
7.2.1 shutdownNow的局限性

7.3 处理百正常的线程终止

7.4 JVM关闭
7.4.1 关闭钩子
7.4.1 守护线程
7.4.1 终结器



第8章 线程池的使用
8.1 在任务与执行策略之间的隐性耦合
8.1.1 线程饥饿死锁
8.1.1 运行时间较长的任务

8.2 设置线程池的大小 
8.3 配置 ThreadPoolExecutor
8.3.1 线程的创建 与销毁
8.3.1 管理队列任务
8.3.1 饱和策略
8.3.1 线程工厂
8.3.1 在调用 构造函数后再定制 ThreadPoolExecutor

8.4 扩展 ThreadPoolExecutor
8.5 递归算法的并行化

















# 16 Java 内存模型
本书中，我们尽可能地避开了Java（JMM）内存模型人底层细节，而将重点放在一些高层设计问题，例如安全发布，同步策略的规范以及一致性等。它们的安全性都来自于JMM，并且当你理解了这些机制的工作原理后，就能更容易地使用它们。本章将介绍Java内存模型的底层需求以及所提供的保证，此外还将介绍在本书给出的一些高层设计原则背后的原理。

## 16.1 什么是内存模型，为什么需要它
    假设一个线程为变量aVariable赋值：
    aVariable = 3;

内存模型需要解决这个问题：“什么条件下，读取 aVariable 的线程将看到这个值为 3？”这听起来似乎是一个愚蠢的问题，但如果 缺少同步，那么将会有许多因素使得线程无法立即甚至永远，看到另一个线程的操作结果。在编译器中生成的指令顺序，可以与源代码中的顺序不同，此外编译器还会把变量保存在寄存器而不是内存中处理器可以采用乱序或并行等方式 来执行指令；缓存可能会改变将写入变量提交到主内存的次序；而且，保存在处理器本地缓存中的值，对于其他处理器是不可见的。这些因素都会使得一个线程无法看到变量的最新值，并且会导致其它线程中的内存操作似乎在乱序执行———— 如果没有使用正确的同步。

在单线程环境中， 我们无法看到所有这些底层技术，它们除了提高程序的执行速度外， 不会产生其它影响。Java语言规范要求JVM在线程中维护一种类似串行的语义：只要程序的最终结果与在严格串行环境中的执行的结果 相同，那么上述所有操作都是允许的。这确实是一件好事情，因为在最近几年中，计算性能的提升在很大程度上要归功于这些重新排序措施。当然，时钟频率的提供同样提升了性能，此外还有不断提升的并行性-- 采用流水线的超标量执行单元，动态指令调度，猜测执行以及完备的多级缓存。随着处理变得越来越强大，编译器也在不断地改进：通过对指令重新排序来实现优化执行，以及使用成熟的全局寄存器分配算法。由于时钟频率越来越难以提高，因此许多处理器制造厂商都开始转而生产多核处理器，因为能够提高的只有硬件并行性。

在多线程环境中，维护程序的串行性将导致很大的性能开销。对于并发应用程序中的线程来说，它们在大部分时间里都执行各自的任务，因此在线程之间的协调操作只会降低应用程序的运行速度，而不会带来任务好处。只有当多个线程要共享数据时，才必须协调它们之间的操作，并且JVM依赖程序通过同步操作来找出这些协调操作将在何时发生。

JMMf规定了JVM必须遵循一组最小保证，这组保证规定了对变量的写入操作在何时将对于其它线程可见。JMM在设计时就在可预测性和程序的易于开发性之间进行了权衡，从而在各种主流的处理器体系架构上能实现高性能的JVM。如果你不了解在现代处理器和编译器中使用的程序性能提升措施，那么在刚刚接触JMM的某些方面时会感到困惑。

### 16.1.1 平台的内存模型

在共享内存的多处理器体系架构中， 每个处理器都拥有自己的缓存，并且定期地与主内存进行协调。在不同的处理器架构中提供了不同级别的缓存一致性（Cache Coherence），其中一部分只提供最小的保证，即允许不同的处理器在任意时刻从同一个存储位置上看到不同的值。操作系统、编译器以及运行时（有时甚至包括应用程序）需要弥合这种在硬件能力与线程安全需求之间的差异。

要想确保每个处理器都能在任意时刻知道其它处理器正在进行的工作，将需要非常大的开销。在大多数时间里，这种信息是不必要的，因此处理器会适当放宽存储一致性保证，以换取性能的提升。在架构定义 的内存模型中将告诉应用程序可以从内存系统中获得怎样的保证，些外还定义了一些特殊的指令（称为内存栅栏或栅栏），当需要共享数据时， 这些指令就能实现额外的存储协调保证。为了使Java开发人员无须关心不同架构上内存模型之间的差异，Java还提供了自己的内存模型。并且JVM通过在适当的位置上插入内存栅栏来屏蔽在JMM与底层平台内存模型之间的差异。

程序执行一种简单假设：想象在程序中只存在唯一的操作执行顺序，而不考虑这些操作在体积处理器上执行，并且在每次 读取变量时，都 能获得在执行序列中（任何处理器）最近 一次写入该变量的值。这种乐观的模型就被称为串行一致性。软件开发人员经常会错误地假设存在串行一致性，但在任何一款现代多处理器架构中都不会提供这种串行一致性，JMM也是如此。冯诺伊曼模型这种经典的串行计算模型，只能近似描述现代多处理器的行为。

在现代支持共享内存的多处理器（和编译器）中，当跨线程共享数据时， 会出现一些奇怪的情况，除非通过使用内存栅栏防止这些情况的发生。幸运的是，Java程序不需要 