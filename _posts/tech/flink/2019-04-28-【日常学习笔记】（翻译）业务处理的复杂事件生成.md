---
layout: post
title:  "【日常学习笔记】（翻译）业务处理的复杂事件生成"
date:   2019-04-23 14:00:00 +0800
tags:
        - 流处理
        - Flink
---

原文参考： [Complex Event Generation for Business Process Monitoring using Apache Flink](https://jobs.zalando.com/tech/blog/complex-event-generation-for-business-process-monitoring-using-apache-flink/)


## 业务处理
一开始，来看看我们要监控的业务处理。

简单地说，一个业务处理就是一个相关事件的链。有一个开始事件和一个完成事件。

(Start event:ORDER_CREATED) ----> (completion event:ALL_PARCELS_SHIPPED)

这个例子中，开始事件是 ORDER_CREATED。 这个事件是用户下了一个订单时生成的，可以用 JSON 来表示：
```json
{
 "event_type":          "ORDER_CREATED",
 "event_id":            1,
 "occurred_at":         "2017-04-18T20:00:00.000Z",
 "order_number":        123
}
```

完成事件是 ALL_PARCELS_SHIPPED， 表示一个订单所有的包裹都已经发出。 可以用 JSON 来表示：
```json
{
 "event_type":      "ALL_PARCELS_SHIPPED",
 "event_id":        11,
 "occurred_at":     "2017-04-19T08:00:00.000Z",
 "order_number":    123
}
```

可以注意到， 事件中都都包含着  order_number， 事件发生的时间 occurred_at。
我们可以监控ORDER_CREATED、 ALL_PARCELS_SHIPPED两个事件的时间间隔。 如果我们指定一个阈值，比如7天， 我们就可以判断哪个订单已经超过了这个阈值， 并采取措施确保包裹立即发出，以让用户满意。

## Problem Statement

复杂事件是从其它若干事件出现的模式中提取出来的一个事件。

在我们的业务处理中， ALL_PARCELS_SHIPPED事件。 事件是由PARCEL_SHIPPED 事件推出来的： 在7天内接收到了订单所有的包裹的 PARCEL_SHIPPED 事件就会生成订单的  ALL_PARCELS_SHIPPED事件。 如果7天内没有能接收到所有包裹的 PARCEL_SHIPPED 事件，我们就要生成一个 THRESHOLD_EXCEEDED 提醒事件。

我们假设我们已经知道一个订单的有多少包裹需要发出， 这个信息 作为一个额外属性包含在 ORDER_CREATED 事件中：  "parcels_to_ship":  3。

还有就是我们假设事件流是有序的， 即 ORDER_CREATED 事件的时间戳 occurred_at 比 其它所有的 PARCEL_SHIPPED 事件时间戳都小。

另外我们需要 复杂事件 ALL_PARCELS_SHIPPED 时间戳设置为 最后一个 PARCEL_SHIPPED 事件的时间戳。

可以表示为下面的流程图：
![TODO](https://zalando-jobsite.cdn.prismic.io/zalando-jobsite/303f8595f80d78c0f6b72555e7acbd2f5054f216_ceg-flowchart1.png)

We process all events from separate Apache Kafka topics using Apache Flink. For a more detailed look of our architecture for business process monitoring, please have a look here.
我们从 Kafka 来获取所有的事件， [关于监控的详细构架，可以参考这里](https://www.slideshare.net/ZalandoTech/stream-processing-using-apache-flink-in-zalandos-world-of-microservices-reactive-summit/33)

## 生成复杂事件

We now have all the required prerequisites to solve the problem at hand, which is to generate the complex events ALL_PARCELS_SHIPPED and THRESHOLD_EXCEEDED.

现在我们已经收集到了生成复杂事件  ALL_PARCELS_SHIPPED 和 THRESHOLD_EXCEEDED 所有的需求。
首先，快速看一下 Flink job 的大概实现：

![](https://zalando-jobsite.cdn.prismic.io/zalando-jobsite/e71070614b2798f2448d06139c8eb4594c70dce1_ceg_blog_post_photo.jpg)

1. 读取 Kafka 的主题：  ORDER_CREATED 与 PARCEL_SHIPPED
2. 为事件时间指定水位
3. 根据 order_number 将相同订单的所有事件都分到一个组。
4. 指定自定义的时间触发器：  TumblingEventTimeWindows 
5. 触发器触发窗口计算后，将窗口内的事件进行排序。 触发器用来检查水位是否超出了窗口的最大时间，这可以保证窗口已经接收到了足够的事件进行排序。
6. 再指定一个带有指定数量和时间触发器的7天大小的 TumblingEventTimeWindow 。
7. 或者通过数数量来判断是否生成 ALL_PARCELS_SHIPPED 事件，也可以通过时间判断是否生成 THRESHOLD_EXCEEDED 事件。 这个数量是从相同窗口的 ORDER_CREATED 事件中的"parcels_to_ship"属性中提取的。
8. 将包含了 ALL_PARCELS_SHIPPED 事件和 THRESHOLD_EXCEEDED事件的流分成两个流，并写入不同的 Kafka topics。

简要的代码如下：

```java
// 1
List<String> topicList = new ArrayList<>();
topicList.add("ORDER_CREATED");
topicList.add("PARCEL_SHIPPED");
DataStream<JSONObject> streams = env.addSource(
      new FlinkKafkaConsumer09<>(topicList, new SimpleStringSchema(), properties))
      .flatMap(new JSONMap()) // parse Strings to JSON
```

```java
// 2-5
DataStream<JSONObject> orderingWindowStreamsByKey = streams
      .assignTimestampsAndWatermarks(new EventsWatermark(topicList.size()))
      .keyBy(new JSONKey("order_number"))
      .window(TumblingEventTimeWindows.of(Time.days(7)))
      .trigger(new OrderingTrigger<>())
      .apply(new CEGWindowFunction<>());
```


```java
// 6-7
DataStream<JSONObject> enrichedCEGStreams = orderingWindowStreamsByKey
     .keyBy(new JSONKey("order_number"))
     .window(TumblingEventTimeWindows.of(Time.days(7)))
     .trigger(new CountEventTimeTrigger<>())
     .reduce((ReduceFunction<JSONObject>) (v1, v2) -> v2); // always return last element
```

```java
// 8
enrichedCEGStreams
      .flatMap(new FilterAllParcelsShipped<>())
      .addSink(new FlinkKafkaProducer09<>(Config.allParcelsShippedType, 
         new SimpleStringSchema(), properties)).name("sink_all_parcels_shipped");
enrichedCEGStreams
      .flatMap(new FilterThresholdExceeded<>())
      .addSink(new FlinkKafkaProducer09<>(Config.thresholdExceededType,
         newSimpleStringSchema(), properties)).name("sink_threshold_exceeded");
```


## 一些挑战

### CEG的触发条件要求有事件的有序性
我们需要将最后一个 PARCEL_SHIPPED 事件的事件时间设置为 ALL_PARCELS_SHIPPED 事件的事件时间。 这样 CountEventTimeTrigger 的触发条件就需要窗口内的事件是有序的，以找到最后一个 PARCEL_SHIPPED 事件。

我们在2-5步中实现了排序。 当一个事件到来，状态会将所有事件中的最大事件时间保存起来。 在注册时，触发器校验水位是否已经超过最大时间戳。 如果超过了， 说明窗口已经收集到了足够用来排序的事件。 我们通过将水位只设置在所有事件最早的时间戳上来保证这一点。 需要注意的，这个操作是很昂贵的， 因为需要将看有的排序事件保存在内存状态中。


### 事件到达窗口的速度不一致
我们从两个Kafka 主题 ORDER_CREATED 和 PARCEL_SHIPPED 读取事件流。 前面一个要比后一个大很多，这样，前面一个主题的读取速率就会比后一个慢。

事件到达窗口的速度不同。这影响着业务逻辑的实现， 尤其是 OrderingTrigger 的触发条件。 它通过将最小的时间戳作为水位来等待两个事件类型到相同的时间戳。 事件会堆积在窗口状态中，直到触发器触发并清除它们。 如果 ORDER_CREATED 主题中的事件是从 1月3号开始的， PARCEL_SHIPPED主题中的事件是从1月1号开始的。 后面的事件会一直堆积在窗口中，直到Flink在1月3号处理到了前面一个队列时才会清除它们。这会消耗大量的内存。

### 在计算开始时可能会生成一些错误的事件
限于资源，我们不可以将事件一直保存在Kafka队列中，过期的事件被被丢弃。 当我们启动Flink作业时，无法获得那些过期的事件。 因为数据丢失，就会造成一些复杂事件无法生成，或者生成错误的事件。 比如 丢失了 PARCEL_SHIPPED 事件，会生成一个 THRESHOLD_EXCEEDED 事件，而不是 ALL_PARCELS_SHIPPED 事件。


### Real data is big and messy. Test with sample data first
### 真实数据是大而混乱的，测试时先使用样本数据。
一开始，我们使用真实数据来测试我们的Flink作业，并推导我们的逻辑。 我们发现这在调试触发器逻辑时是低效不方便的。 有些事件丢失了，有些是属性值不正确的。 在第一次迭代中造成了不必要的困难。 后面，我们就了自定义的 source 函数，来模拟真实数据的行为，并研究复杂事件的生成。

### Data is sometimes too big for reprocessing
复杂事件丢失说明我们需要通过再处理全部的Kafka主题输入来再次生成复杂事件，主题一般可以保存30天的事件。 这种再处理对我们来说不太可能实现。 因为CEG的触发条件需要有序的事件， 而事件的读取速率不同， 随着处理时间的增长，内存的消耗也不断增长。 事件堆积在窗口状态里，等待着水位的推进以便触发器触发并清除他们。

在我们的测试集群中，我们使用 AWS EC2 t2.medium，分配1GB的内存。 我们观察到， 最多可以重新处理2天的数据，而不会引起内存不足让 TaskManager 崩溃。 因此我们对早期事件进行了额外的过滤。

## 结论
上面说明我们是如何设计和实现复杂事件（ALL_PARCELS_SHIPPED 、 THRESHOLD_EXCEEDED）的。 演示了如何使用Flink的事件时间处理能力来实时生成复杂事件。 亦展示了一些我们在使用FLink强大的事件时间处理功能时遇到的挑战， 如， 水位，事件时间窗口和自定义触发器。

有经验的读者可能知道 Flink 提供的 CEP 库。 在我们开始我们的用例时（Flink1.1），我们判断这不会是容易实现的。 我们相信自己来控制触发器能够带来更多的灵活性，以便不断地迭代提炼我们的模式。 现在，CEP库已经成熟（Flink1.4）， 在CEP的模式中也已经支持动态状态变更。 可以更方便地实现与我们的类似的用例了。
